{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "import cv2\n",
    "import skimage\n",
    "import os\n",
    "import random\n",
    "from imgaug.imgaug import augmenters as iaa\n",
    "from densenet121 import DenseNet\n",
    "from sklearn import decomposition\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Data Augmentation Methods\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)), # blur images with a sigma of 0 to 3.0\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)),\n",
    "    iaa.Add((-30, 30)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Superpixels(p_replace=0.5, n_segments=64),\n",
    "    iaa.Dropout(p=(0, 0.2)),\n",
    "    iaa.Affine(rotate=(-45, 45))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class image_util:\n",
    "    def __init__(self, data_dir, biz_label_file_name, photo_biz_file_name):\n",
    "        self.batch_index = 0\n",
    "        self.image_paths = [os.path.join(data_dir,i) for i in os.listdir(data_dir) if i.endswith('.jpg') and not i.startswith(\"._\")]\n",
    "        random.shuffle(self.image_paths)\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.image_len = len(self.image_paths)\n",
    "        self.one_hot = self.read_csv_one_hot(biz_label_file_name)\n",
    "        self.photo_biz = self.photo_to_biz_id(photo_biz_file_name)\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        images = []\n",
    "        labels = []\n",
    "        #upon calling next batch, a batch of data is read from disk\n",
    "        #When reaches last batch, the conter will be updated to form a non-stop data input\n",
    "        if (self.batch_index+1) * batch_size < self.image_len:\n",
    "            start = self.batch_index * batch_size\n",
    "            end = batch_size + start\n",
    "            ## construct the image batch and labels\n",
    "            for path in self.image_paths[start:end]:\n",
    "                img = cv2.imread(path)\n",
    "                photo_id = os.path.basename(path).split(\".\")[0]\n",
    "                self.labels.append(self.one_hot[self.photo_biz[photo_id]])\n",
    "                img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(self.one_hot[self.photo_biz[photo_id]])\n",
    "            images_inputs = []\n",
    "            for im in images:\n",
    "                im = cv2.resize(im, (224,224)).astype(np.float32)\n",
    "                im[:,:,0] = (im[:,:,0] - 103.94) * 0.017\n",
    "                im[:,:,1] = (im[:,:,1] - 116.78) * 0.017\n",
    "                im[:,:,2] = (im[:,:,2] - 123.68) * 0.017\n",
    "                images_inputs.append(im)\n",
    "            images = np.asarray(images_inputs)\n",
    "            labels = np.asarray(labels)\n",
    "            self.batch_index += 1\n",
    "            return images, labels\n",
    "        else:\n",
    "            self.batch_index = 0\n",
    "            start = self.batch_index * batch_size\n",
    "            end = batch_size + start\n",
    "            for path in self.image_paths[start:end]:\n",
    "                img = cv2.imread(path)\n",
    "                photo_id = os.path.basename(path).split(\".\")[0]\n",
    "                self.labels.append(self.one_hot[self.photo_biz[photo_id]])\n",
    "                img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                labels.append(self.one_hot[self.photo_biz[photo_id]])\n",
    "            images_inputs = []\n",
    "            for im in images:\n",
    "                im = cv2.resize(im, (224,224)).astype(np.float32)\n",
    "                im[:,:,0] = (im[:,:,0] - 103.94) * 0.017\n",
    "                im[:,:,1] = (im[:,:,1] - 116.78) * 0.017\n",
    "                im[:,:,2] = (im[:,:,2] - 123.68) * 0.017\n",
    "                images_inputs.append(im)\n",
    "            images = np.asarray(images_inputs)\n",
    "            images = np.asarray(images)\n",
    "            labels = np.asarray(labels)\n",
    "            return images, labels\n",
    "        \n",
    "    def read_csv_one_hot(self, file_name):\n",
    "        ## return a dict where key is business id and value is encoded business label\n",
    "        with open(file_name,\"r\") as f:\n",
    "            lines = f.readlines()[1:]\n",
    "        biz_id_to_label = {}\n",
    "        for line in lines:\n",
    "            try:\n",
    "                biz_id_to_label[line.split(\",\")[0]] = np.zeros(9)\n",
    "                for label in line.split(\",\")[1].rstrip().split(' '):\n",
    "                    biz_id_to_label[line.split(\",\")[0]][int(label)]=1\n",
    "            except:\n",
    "                if not line.split(\",\")[1].rstrip():\n",
    "                    continue\n",
    "        return biz_id_to_label\n",
    "    \n",
    "    def photo_to_biz_id(self, file_name):\n",
    "        ## return a dict where the key is photo id and value is a list of coresponding business label\n",
    "        with open(file_name,\"r\") as f:\n",
    "            lines = f.readlines()[1:]\n",
    "        photo_to_biz = {}\n",
    "        for line in lines:\n",
    "            photo_to_biz[line.split(\",\")[0]] = line.split(\",\")[1].rstrip() \n",
    "        return photo_to_biz\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Change the data path to your data path\n",
    "util = image_util('./train_photos', './train.csv', './train_photo_to_biz_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This step is optional, and if needed should be implemented in the util.next_batch\n",
    "ims = util.images\n",
    "# do image augmentation\n",
    "for idx in range(10):\n",
    "    # 'images' should be either a 4D numpy array of shape (N, height, width, channels)\n",
    "    # or a list of 3D numpy arrays, each having shape (height, width, channels).\n",
    "    # Grayscale images must have shape (height, width, 1) each.\n",
    "    # All images must have numpy's dtype uint8. Values are expected to be in\n",
    "    # range 0-255.\n",
    "    images_aug = seq.augment_images(util.images)\n",
    "    ims = np.concatenate((ims, images_aug), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_input = []\n",
    "# do normalization and return a tensor of 0 mean and 1 stddev\n",
    "for im in ims:\n",
    "    im = cv2.resize(im, (224,224)).astype(np.float32)\n",
    "    im[:,:,0] = (im[:,:,0] - 103.94) * 0.017\n",
    "    im[:,:,1] = (im[:,:,1] - 116.78) * 0.017\n",
    "    im[:,:,2] = (im[:,:,2] - 123.68) * 0.017\n",
    "    images_input.append(im)\n",
    "images_input = np.asarray(images_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## construct the Pre-trained DenseNet\n",
    "## and reduce the number of feature maps in the transition block to save some compute power\n",
    "model = DenseNet(reduction=0.5, classes=1000, weights_path='./densenet121_weights_tf.h5')\n",
    "print(model.layers[-1].output_shape)\n",
    "## remove Pre-trained Classifer at the end\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "print(model.layers[-1].output_shape)\n",
    "output = model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add our fully connected layer at the end of the model to do classification\n",
    "output = Dense(100, activation='elu', name='fully_last')(output)\n",
    "## use sigmoid as activation for the last layer to generate the un-normalized probablity for each bit of the label\n",
    "output = Dense(9, activation='sigmoid', name='final')(output)\n",
    "new_model = Model(model.input, output)\n",
    "## use momentum to get a smoother convergence\n",
    "sgd = SGD(lr=1e-2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "## use binary-crossentropy to get multilabel classification score.\n",
    "new_model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## start training\n",
    "epoch = 4\n",
    "batch_size = 20\n",
    "display_step = 20\n",
    "new_model.save(\"./new_model_checkpoint.h5\")\n",
    "## for each epoch, train all the images in the training set\n",
    "for i in range(epoch):\n",
    "    for j in range(util.image_len/batch_size):\n",
    "        images, labels = util.next_batch(batch_size)\n",
    "        loss = new_model.train_on_batch(images,labels)\n",
    "        if (i+1)*j%display_step==0:\n",
    "            images, labels = util.next_batch(batch_size)\n",
    "            acc = new_model.test_on_batch(images,labels)\n",
    "            print('Epoch:'+str(i)+'  '+'Batch:'+str(j)+'  '+'Loss:'+str(loss)+'   '+'Accuracy:'+str(acc))\n",
    "        ## for every 100 batches, save a check point\n",
    "        if (i+1)*j%100==0:\n",
    "            new_model.save('./new_model_checkpoint.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
