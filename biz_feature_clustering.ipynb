{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import skimage\n",
    "import os\n",
    "from imgaug.imgaug import augmenters as iaa\n",
    "from densenet121 import DenseNet\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = DenseNet(reduction=0.5, classes=1000, weights_path='./densenet121_weights_tf.h5')\n",
    "print(model.layers[-1].output_shape)\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "output = model.layers[-1].output\n",
    "new_model = Model(model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(features_set, labels_set):\n",
    "    print \"get_data\"\n",
    "    group_element_num = 100\n",
    "    \n",
    "    label_to_features = {}\n",
    "    label_to_indexes = {}\n",
    "    for index, label in enumerate(labels_set):\n",
    "        label = tuple(label)\n",
    "        if label not in label_to_features:\n",
    "            label_to_features[label] = [features_set[index]]\n",
    "            label_to_indexes[label] = [index]\n",
    "        else:\n",
    "            label_to_features[label].append(features_set[index])\n",
    "            label_to_indexes[label].append(index)\n",
    "\n",
    "    labels = []\n",
    "    img_features = []\n",
    "    indexes = []\n",
    "    for l in label_to_features.keys():\n",
    "        if len(label_to_features[l]) % group_element_num == 0:\n",
    "            split = len(label_to_features[l])/group_element_num\n",
    "        else:\n",
    "            split = len(label_to_features[l])/group_element_num + 1\n",
    "        for i in range(split):\n",
    "            labels.append(l)\n",
    "            # if it's the last part\n",
    "            if i == split-1:\n",
    "                img_features.append(np.asarray(label_to_features[l][i*group_element_num:]))\n",
    "                indexes.append(np.asarray(label_to_indexes[l][i*group_element_num:]))\n",
    "            # split into parts, each with 'group_element_num' img featrues\n",
    "            else:\n",
    "                img_features.append(np.asarray(label_to_features[l][i*group_element_num:(i+1)*group_element_num]))\n",
    "                indexes.append(np.asarray(label_to_indexes[l][i*group_element_num:(i+1)*group_element_num]))\n",
    "\n",
    "    labels = np.asarray(labels)\n",
    "    img_features = np.asarray(img_features)\n",
    "    indexes = np.asarray(indexes)\n",
    "    \n",
    "#     return my_shuffle([img_features, labels, indexes])\n",
    "    return img_features, labels, indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(iteration, train_X, train_y):\n",
    "    print \"training\"\n",
    "    # classifier = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "    lst_clfs = [LinearSVC() for i in range(9)]\n",
    "    for i in range(iteration):\n",
    "        print \"Iteration: \" + str(i)\n",
    "        for k in range(9):\n",
    "            clf = lst_clfs[k]\n",
    "            part = train_X.shape[0]/5\n",
    "            scores = []\n",
    "            for fold in range(5):\n",
    "                val_X = train_X[fold*part:(fold+1)*part]\n",
    "                val_y = train_y[fold*part:(fold+1)*part]\n",
    "                tr_X = np.vstack((train_X[0:fold*part], train_X[(fold+1)*part:]))\n",
    "                tr_y = np.vstack((train_y[0:fold*part], train_y[(fold+1)*part:]))\n",
    "\n",
    "                clf.fit(tr_X, tr_y[:, k])\n",
    "                val_score = clf.score(val_X, val_y[:, k])\n",
    "                scores.append(val_score)\n",
    "            print(\"Training accuracy: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))\n",
    "            \n",
    "    return lst_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(lst_clfs, test_X, test_y):\n",
    "    for k in range(9):\n",
    "        clf = lst_clfs[k]\n",
    "        s = clf.score(test_X, test_y[:,k])\n",
    "        print str(k) + \"'s classifier, test acc = \" + str(round(s, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_biz_features(img_features, labels, indexes, num_cluster, kmn):\n",
    "    biz_features = np.zeros([len(labels),(1024*num_cluster)])\n",
    "\n",
    "    for idx, features in enumerate(img_features):\n",
    "        feature_index = indexes[idx]\n",
    "        cluster_lable = np.array(kmn[feature_index])\n",
    "        \n",
    "        # for each biz group, mean feature vectore for those in the same cluster\n",
    "        for kn in range(num_cluster):\n",
    "            x = features[cluster_lable==kn]\n",
    "            # if feature doesn't belong to any cluster,\n",
    "            # which is impossible....\n",
    "            if(len(x) == 0):    \n",
    "                biz_features[idx,(1024*(kn)):(1024*(kn+1))] = np.zeros([1,1024])\n",
    "            else:\n",
    "                x = np.mean(x,axis=0)\n",
    "                x = x.reshape([1,1024])\n",
    "                biz_features[idx,(1024*(kn)):(1024*(kn+1))] = x\n",
    "\n",
    "    return biz_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_shuffle(arr_list):\n",
    "    s_index = np.arange(len(arr_list[0]))\n",
    "    np.random.shuffle(s_index)\n",
    "    return_lst = []\n",
    "    for arr in arr_list:\n",
    "        return_lst.append(arr[s_index])\n",
    "    return tuple(return_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "def one_vs_rest_train_test(train_X, train_y):\n",
    "    classifier = OneVsRestClassifier(LinearSVC(loss='hinge'))\n",
    "    classifier.fit(train_X, train_y)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_features = np.load('/home/rendaxuan/Documents/workspace/4032/features_234000.npy')\n",
    "input_labels = np.load('/home/rendaxuan/Documents/workspace/4032/features_labels_234000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num_cluster in [4]:\n",
    "    print \"num_cluster = \" + str(num_cluster)\n",
    "    # shuffle input data\n",
    "    input_features, input_labels = my_shuffle([input_features, input_labels])\n",
    "    kmn_holder = MiniBatchKMeans(n_clusters=num_cluster)\n",
    "    kmn = kmn_holder.fit_predict(input_features, input_labels)\n",
    "    kmn_train = kmn[:1880000]\n",
    "    kmn_test = kmn[188000:-1000]\n",
    "    train_data = input_features[:188000]\n",
    "    train_label = input_labels[:188000]\n",
    "    test_data = input_features[188000:-1000]\n",
    "    test_label = input_labels[188000:-1000]\n",
    "    tr_img_features, tr_labels, tr_indexes = get_data(train_data, train_label)\n",
    "    tr_biz_features = get_biz_features(tr_img_features, tr_labels, tr_indexes, num_cluster, kmn_train)\n",
    "    ts_img_features, ts_labels, ts_indexes = get_data(test_data,test_label)\n",
    "    ts_biz_features = get_biz_features(ts_img_features, ts_labels, ts_indexes, num_cluster, kmn_test)\n",
    "    classifier = one_vs_rest_train_test(tr_biz_features, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = input_features[-3000:-1000]\n",
    "test_label = input_labels[-3000:-1000]\n",
    "ts_img_features, ts_labels, ts_indexes = my_shuffle(get_data(test_data,test_label))\n",
    "ts_biz_features = get_biz_features(ts_img_features, ts_labels, ts_indexes, num_cluster, kmn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = classifier.predict(ts_biz_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0 \n",
    "for i in range(predict.shape[0]): \n",
    "    if np.array_equal(predict[i], ts_labels[i]): \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count/float(predict.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ele_predict = classifier.score(ts_biz_features, ts_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ele_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# business features\n",
    "def get_img_features(images):\n",
    "    biz_features = []\n",
    "    for i, img_list in enumerate(images):\n",
    "        pred = new_model.predict(img_list)\n",
    "        img_features.append(np.mean(pred, axis=0))\n",
    "    return np.asarray(biz_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " ''' get dictionary of biz_ids and all the corresponding photos '''\n",
    "def biz_id_to_photo(file_name):\n",
    "    with open(file_name,\"r\") as f:\n",
    "        lines = f.readlines()[1:]\n",
    "    biz_to_photo = {}\n",
    "    for line in lines:\n",
    "        if line.split(\",\")[1].rstrip() not in biz_to_photo.keys():\n",
    "            biz_to_photo[line.split(\",\")[1].rstrip()] = [line.split(\",\")[0]]\n",
    "        else:\n",
    "            biz_to_photo[line.split(\",\")[1].rstrip()].append(line.split(\",\")[0])\n",
    "    return biz_to_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_photo_to_biz_df = pd.read_csv('./test_photo_to_biz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img_features = np.load('./features_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "photo_ids = []\n",
    "data_dir = './test_photos/'\n",
    "paths = [os.path.join(data_dir,i) for i in os.listdir(data_dir) if i.endswith('.jpg') and not i.startswith(\"._\")]\n",
    "for path in paths:\n",
    "    photo_ids.append(int(path.replace(data_dir,\"\").replace(\".jpg\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biz_img_features_df = pd.DataFrame(columns=[\"business_id\", \"img_features\"])\n",
    "biz_img_features = {}\n",
    "counter = 0\n",
    "for index, row in test_photo_to_biz_df.iterrows():\n",
    "    if photo_ids.index(row['photo_id']) >= len(test_img_features):\n",
    "        continue\n",
    "    img_feature = test_img_features[photo_ids.index(row['photo_id'])]\n",
    "    if not row['business_id'] in biz_img_features.keys():\n",
    "        biz_img_features[row['business_id']] = [img_feature]\n",
    "    else:\n",
    "        biz_img_features[row['business_id']].append(img_feature)\n",
    "    counter+=1\n",
    "    if counter % 500 == 0:\n",
    "        print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = biz_img_features.values()[0]\n",
    "test_features = np.vstack([np.vstack(biz_img_features[i]) for i in biz_img_features.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for num_cluster in [2,3,4,5]:\n",
    "    print \"num_cluster = \" + str(num_cluster)\n",
    "    input_features, input_labels = my_shuffle([input_features, input_labels])\n",
    "    kmn_holder = MiniBatchKMeans(n_clusters=num_cluster)\n",
    "    kmn = kmn_holder.fit_predict(input_features, input_labels)\n",
    "    kmn_train = kmn[:]\n",
    "    kmn_test_holder = MiniBatchKMeans(n_clusters=num_cluster)\n",
    "    kmn_test = kmn_test_holder.fit_predict(test_features) \n",
    "    train_data = input_features\n",
    "    train_label = input_labels\n",
    "    test_data = test_features\n",
    "    test_label = biz_img_features.keys()\n",
    "    tr_img_features, tr_labels, tr_indexes = get_data(train_data, train_label)\n",
    "    tr_biz_features = get_biz_features(tr_img_features, tr_labels, tr_indexes, num_cluster, kmn_train)\n",
    "    ts_img_features, ts_labels, ts_indexes = get_data(test_data,test_label)\n",
    "    ts_biz_features = get_biz_features(ts_img_features, ts_labels, ts_indexes, num_cluster, kmn_test)   \n",
    "    classifier = one_vs_rest_train_test(tr_biz_features, tr_labels)\n",
    "    predict = classifier.predict(tr_biz_features[:20])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0: good_for_lunch\n",
    "# 1: good_for_dinner\n",
    "# 2: takes_reservations\n",
    "# 3: outdoor_seating\n",
    "# 4: restaurant_is_expensive\n",
    "# 5: has_alcohol\n",
    "# 6: has_table_service\n",
    "# 7: ambience_is_classy\n",
    "# 8: good_for_kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_indexes[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_indexes.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
