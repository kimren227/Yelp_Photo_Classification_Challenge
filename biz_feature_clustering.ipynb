{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import skimage\n",
    "import os\n",
    "from imgaug.imgaug import augmenters as iaa\n",
    "from densenet121 import DenseNet\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1000)\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet(reduction=0.5, classes=1000, weights_path='./densenet121_weights_tf.h5')\n",
    "print(model.layers[-1].output_shape)\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "output = model.layers[-1].output\n",
    "new_model = Model(model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1024)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.layers[-1].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(features_set, labels_set):\n",
    "    print \"get_data\"\n",
    "    group_element_num = 100\n",
    "    \n",
    "    label_to_features = {}\n",
    "    label_to_indexes = {}\n",
    "    for index, label in enumerate(labels_set):\n",
    "        label = tuple(label)\n",
    "        if label not in label_to_features:\n",
    "            label_to_features[label] = [features_set[index]]\n",
    "            label_to_indexes[label] = [index]\n",
    "        else:\n",
    "            label_to_features[label].append(features_set[index])\n",
    "            label_to_indexes[label].append(index)\n",
    "\n",
    "    labels = []\n",
    "    img_features = []\n",
    "    indexes = []\n",
    "    for l in label_to_features.keys():\n",
    "        if len(label_to_features[l]) % group_element_num == 0:\n",
    "            split = len(label_to_features[l])/group_element_num\n",
    "        else:\n",
    "            split = len(label_to_features[l])/group_element_num + 1\n",
    "        for i in range(split):\n",
    "            labels.append(l)\n",
    "            # if it's the last part\n",
    "            if i == split-1:\n",
    "                img_features.append(np.asarray(label_to_features[l][i*group_element_num:]))\n",
    "                indexes.append(np.asarray(label_to_indexes[l][i*group_element_num:]))\n",
    "            # split into parts, each with 'group_element_num' img featrues\n",
    "            else:\n",
    "                img_features.append(np.asarray(label_to_features[l][i*group_element_num:(i+1)*group_element_num]))\n",
    "                indexes.append(np.asarray(label_to_indexes[l][i*group_element_num:(i+1)*group_element_num]))\n",
    "\n",
    "    labels = np.asarray(labels)\n",
    "    img_features = np.asarray(img_features)\n",
    "    indexes = np.asarray(indexes)\n",
    "    \n",
    "    return my_shuffle([img_features, labels, indexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(iteration, train_X, train_y):\n",
    "    print \"training\"\n",
    "    # classifier = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "    lst_clfs = [LinearSVC() for i in range(9)]\n",
    "    for i in range(iteration):\n",
    "        print \"Iteration: \" + str(i)\n",
    "        for k in range(9):\n",
    "            clf = lst_clfs[k]\n",
    "            part = train_X.shape[0]/5\n",
    "            scores = []\n",
    "            for fold in range(5):\n",
    "                val_X = train_X[fold*part:(fold+1)*part]\n",
    "                val_y = train_y[fold*part:(fold+1)*part]\n",
    "                tr_X = np.vstack((train_X[0:fold*part], train_X[(fold+1)*part:]))\n",
    "                tr_y = np.vstack((train_y[0:fold*part], train_y[(fold+1)*part:]))\n",
    "\n",
    "                clf.fit(tr_X, tr_y[:, k])\n",
    "                val_score = clf.score(val_X, val_y[:, k])\n",
    "                scores.append(val_score)\n",
    "            print(\"Training accuracy: %0.2f (+/- %0.2f)\" % (np.mean(scores), np.std(scores) * 2))\n",
    "            \n",
    "    return lst_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(lst_clfs, test_X, test_y):\n",
    "    for k in range(9):\n",
    "        clf = lst_clfs[k]\n",
    "        s = clf.score(test_X, test_y[:,k])\n",
    "        print str(k) + \"'s classifier, test acc = \" + str(round(s, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_biz_features(img_features, labels, indexes, num_cluster, kmn):\n",
    "    biz_features = np.zeros([len(labels),(1024*num_cluster)])\n",
    "\n",
    "    for idx, features in enumerate(img_features):\n",
    "        feature_index = indexes[idx]\n",
    "        cluster_lable = np.array(kmn[feature_index])\n",
    "        \n",
    "        # for each biz group, mean feature vectore for those in the same cluster\n",
    "        for kn in range(num_cluster):\n",
    "            x = features[cluster_lable==kn]\n",
    "            # if feature doesn't belong to any cluster,\n",
    "            # which is impossible....\n",
    "            if(len(x) == 0):    \n",
    "                biz_features[idx,(1024*(kn)):(1024*(kn+1))] = np.zeros([1,1024])\n",
    "            else:\n",
    "                x = np.mean(x,axis=0)\n",
    "                x = x.reshape([1,1024])\n",
    "                biz_features[idx,(1024*(kn)):(1024*(kn+1))] = x\n",
    "\n",
    "    return biz_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_shuffle(arr_list):\n",
    "    s_index = np.arange(len(arr_list[0]))\n",
    "    np.random.shuffle(s_index)\n",
    "    return_lst = []\n",
    "    for arr in arr_list:\n",
    "        return_lst.append(arr[s_index])\n",
    "    return tuple(return_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "def one_vs_rest_train_test(train_X, train_y):\n",
    "    \n",
    "    # classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "    classifier = OneVsRestClassifier(LinearSVC(loss='hinge'))\n",
    "    classifier.fit(train_X, train_y)\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "    print \"test\"\n",
    "    return classifier\n",
    "#     print \"F1 score: \", f1_score(test_y, y_predict, average='micro')\n",
    "#     print \"Individual Class F1 score: \", f1_score(test_y, y_predict, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_features = np.load('/home/rendaxuan/Documents/workspace/4032/features_234000.npy')\n",
    "input_labels = np.load('/home/rendaxuan/Documents/workspace/4032/features_labels_234000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cluster = 2\n",
      "get_data\n",
      "get_data\n",
      "test\n",
      "F1 score:  0.999397711303\n",
      "Individual Class F1 score:  [ 1.          1.          0.99695122  1.          1.          1.\n",
      "  0.99875776  1.          1.        ]\n",
      "num_cluster = 3\n",
      "get_data\n",
      "get_data\n",
      "test\n",
      "F1 score:  0.997997597117\n",
      "Individual Class F1 score:  [ 1.          1.          0.9969697   0.9981378   0.99764706  0.99607843\n",
      "  1.          0.99494949  0.99808795]\n",
      "num_cluster = 4\n",
      "get_data\n",
      "get_data\n",
      "test\n",
      "F1 score:  0.997585513078\n",
      "Individual Class F1 score:  [ 0.99595142  0.99841521  0.9969419   0.99625468  0.997669    0.998679\n",
      "  0.99875156  1.          0.99426386]\n",
      "num_cluster = 5\n",
      "get_data\n",
      "get_data\n",
      "test\n",
      "F1 score:  0.998990918264\n",
      "Individual Class F1 score:  [ 0.99595142  0.9984051   1.          0.99812383  1.          0.9986755   1.\n",
      "  1.          0.99806576]\n"
     ]
    }
   ],
   "source": [
    "for num_cluster in [2,3,4,5]:\n",
    "    print \"num_cluster = \" + str(num_cluster)\n",
    "    # shuffle input data\n",
    "#     input_features, input_labels = shuffle(input_features, input_labels, random_state=7)\n",
    "    \n",
    "    input_features, input_labels = my_shuffle([input_features, input_labels])\n",
    "    \n",
    "    kmn_holder = MiniBatchKMeans(n_clusters=num_cluster)\n",
    "    kmn = kmn_holder.fit_predict(input_features, input_labels)\n",
    "    kmn_train = kmn[:1880000]\n",
    "    kmn_test = kmn[188000:]\n",
    "    \n",
    "    train_data = input_features[:188000]\n",
    "    train_label = input_labels[:188000]\n",
    "    \n",
    "    test_data = input_features[188000:]\n",
    "    test_label = input_labels[188000:]\n",
    "    \n",
    "    tr_img_features, tr_labels, tr_indexes = get_data(train_data, train_label)\n",
    "    tr_biz_features = get_biz_features(tr_img_features, tr_labels, tr_indexes, num_cluster, kmn_train)\n",
    "\n",
    "    ts_img_features, ts_labels, ts_indexes = get_data(test_data,test_label)\n",
    "    ts_biz_features = get_biz_features(ts_img_features, ts_labels, ts_indexes, num_cluster, kmn_test)\n",
    "\n",
    "    #     for idx, features in enumerate(img_features):\n",
    "#         feature_index = indexes[idx]\n",
    "#         cluster_lable = np.array(kmn_train[feature_index])\n",
    "        \n",
    "#         # for each biz group, mean feature vectore for those in the same cluster\n",
    "#         for kn in range(num_cluster):\n",
    "#             x = features[cluster_lable==kn]\n",
    "#             # if feature doesn't belong to any cluster,\n",
    "#             # which is impossible....\n",
    "#             if(len(x) == 0):    \n",
    "#                 biz_features[idx,(1024*(kn)):(1024*(kn+1))] = np.zeros([1,1024])\n",
    "#             else:\n",
    "#                 x = np.mean(x,axis=0)\n",
    "#                 x = x.reshape([1,1024])\n",
    "#                 biz_features[idx,(1024*(kn)):(1024*(kn+1))] = x\n",
    "    \n",
    "    one_vs_rest_train_test(tr_biz_features, tr_labels, ts_biz_features, ts_labels)\n",
    "#     list_of_classifiers = train(1, tr_biz_features, tr_labels)\n",
    "    \n",
    "#     test(list_of_classifiers, ts_biz_features, ts_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# business features\n",
    "def get_img_features(images):\n",
    "    biz_features = []\n",
    "    for i, img_list in enumerate(images):\n",
    "        pred = new_model.predict(img_list)\n",
    "#         print('hiuhiuhiu')\n",
    "        img_features.append(np.mean(pred, axis=0))\n",
    "    return np.asarray(biz_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " ''' get dictionary of biz_ids and all the corresponding photos '''\n",
    "def biz_id_to_photo(file_name):\n",
    "    with open(file_name,\"r\") as f:\n",
    "        lines = f.readlines()[1:]\n",
    "    biz_to_photo = {}\n",
    "    for line in lines:\n",
    "        if line.split(\",\")[1].rstrip() not in biz_to_photo.keys():\n",
    "            biz_to_photo[line.split(\",\")[1].rstrip()] = [line.split(\",\")[0]]\n",
    "        else:\n",
    "            biz_to_photo[line.split(\",\")[1].rstrip()].append(line.split(\",\")[0])\n",
    "    return biz_to_photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_photo_to_biz_df = pd.read_csv('./test_photo_to_biz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_img_features = np.load('./features_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "photo_ids = []\n",
    "data_dir = './test_photos/'\n",
    "paths = [os.path.join(data_dir,i) for i in os.listdir(data_dir) if i.endswith('.jpg') and not i.startswith(\"._\")]\n",
    "for path in paths:\n",
    "    photo_ids.append(int(path.replace(data_dir,\"\").replace(\".jpg\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biz_img_features_df = pd.DataFrame(columns=[\"business_id\", \"img_features\"])\n",
    "biz_img_features = {}\n",
    "counter = 0\n",
    "for index, row in test_photo_to_biz_df.iterrows():\n",
    "    if photo_ids.index(row['photo_id']) >= len(test_img_features):\n",
    "        continue\n",
    "    img_feature = test_img_features[photo_ids.index(row['photo_id'])]\n",
    "    if not row['business_id'] in biz_img_features.keys():\n",
    "        biz_img_features[row['business_id']] = [img_feature]\n",
    "    else:\n",
    "        biz_img_features[row['business_id']].append(img_feature)\n",
    "    counter+=1\n",
    "    if counter % 500 == 0:\n",
    "        print counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features = biz_img_features.values()[0]\n",
    "test_features = np.vstack([np.vstack(biz_img_features[i]) for i in biz_img_features.keys()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cluster = 2\n",
      "get_data\n",
      "get_data\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for num_cluster in [2,3,4,5]:\n",
    "    print \"num_cluster = \" + str(num_cluster)\n",
    "    # shuffle input data\n",
    "#     input_features, input_labels = shuffle(input_features, input_labels, random_state=7)\n",
    "    \n",
    "    input_features, input_labels = my_shuffle([input_features, input_labels])\n",
    "    \n",
    "    kmn_holder = MiniBatchKMeans(n_clusters=num_cluster)\n",
    "    kmn = kmn_holder.fit_predict(input_features, input_labels)\n",
    "    kmn_train = kmn[:]\n",
    "    kmn_test_holder = MiniBatchKMeans(n_clusters=num_cluster)\n",
    "    kmn_test = kmn_test_holder.fit_predict(test_features) \n",
    "    \n",
    "    train_data = input_features\n",
    "    train_label = input_labels\n",
    "    \n",
    "    test_data = test_features\n",
    "    test_label = biz_img_features.keys()\n",
    "    \n",
    "    tr_img_features, tr_labels, tr_indexes = get_data(train_data, train_label)\n",
    "    tr_biz_features = get_biz_features(tr_img_features, tr_labels, tr_indexes, num_cluster, kmn_train)\n",
    "\n",
    "    ts_img_features, ts_labels, ts_indexes = get_data(test_data,test_label)\n",
    "    ts_biz_features = get_biz_features(ts_img_features, ts_labels, ts_indexes, num_cluster, kmn_test)\n",
    "\n",
    "    #     for idx, features in enumerate(img_features):\n",
    "#         feature_index = indexes[idx]\n",
    "#         cluster_lable = np.array(kmn_train[feature_index])\n",
    "        \n",
    "#         # for each biz group, mean feature vectore for those in the same cluster\n",
    "#         for kn in range(num_cluster):\n",
    "#             x = features[cluster_lable==kn]\n",
    "#             # if feature doesn't belong to any cluster,\n",
    "#             # which is impossible....\n",
    "#             if(len(x) == 0):    \n",
    "#                 biz_features[idx,(1024*(kn)):(1024*(kn+1))] = np.zeros([1,1024])\n",
    "#             else:\n",
    "#                 x = np.mean(x,axis=0)\n",
    "#                 x = x.reshape([1,1024])\n",
    "#                 biz_features[idx,(1024*(kn)):(1024*(kn+1))] = x\n",
    "    \n",
    "    classifier = one_vs_rest_train_test(tr_biz_features, tr_labels)\n",
    "    predict = classifier.predict(tr_biz_features[:20])\n",
    "#     predict = classifier.predict(ts_biz_features)\n",
    "    break\n",
    "#     list_of_classifiers = train(1, tr_biz_features, tr_labels)\n",
    "    \n",
    "#     test(list_of_classifiers, ts_biz_features, ts_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "0: good_for_lunch\n",
    "1: good_for_dinner\n",
    "2: takes_reservations\n",
    "3: outdoor_seating\n",
    "4: restaurant_is_expensive\n",
    "5: has_alcohol\n",
    "6: has_table_service\n",
    "7: ambience_is_classy\n",
    "8: good_for_kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 1, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 0, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 0, 0]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.],\n",
       "       [ 1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,  1.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_labels[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([212477, 212523, 212525, 212541, 212583, 212604, 212612, 212623,\n",
       "       212638, 212660, 212661, 212685, 212699, 212739, 212741, 212765,\n",
       "       212787, 212815, 212834, 212860, 212869, 212870, 212873, 212883,\n",
       "       212886, 212911, 212938, 212946, 212958, 212972, 213010, 213011,\n",
       "       213016, 213018, 213050, 213057, 213069, 213092, 213100, 213105,\n",
       "       213139, 213150, 213156, 213157, 213164, 213174, 213182, 213210,\n",
       "       213270, 213313, 213335, 213355, 213361, 213373, 213378, 213393,\n",
       "       213394, 213396, 213413, 213451, 213489, 213493, 213521, 213525,\n",
       "       213531, 213550, 213563, 213566, 213605, 213611, 213615, 213623,\n",
       "       213649, 213651, 213668, 213678, 213700, 213712, 213716, 213726,\n",
       "       213731, 213757, 213759, 213806, 213858, 213900, 213913, 213927,\n",
       "       213929, 213953, 213980, 214014, 214028, 214037, 214106, 214127,\n",
       "       214128, 214171, 214180, 214229])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_indexes[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2402,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
