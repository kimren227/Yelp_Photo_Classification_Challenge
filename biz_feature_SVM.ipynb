{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import cv2\n",
    "import skimage\n",
    "import os\n",
    "from imgaug.imgaug import augmenters as iaa\n",
    "from densenet121 import DenseNet\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = iaa.Sequential([\n",
    "    iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n",
    "    iaa.GaussianBlur(sigma=(0, 3.0)), # blur images with a sigma of 0 to 3.0\n",
    "    iaa.CropAndPad(percent=(-0.25, 0.25)),\n",
    "    iaa.Add((-30, 30)),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Superpixels(p_replace=0.5, n_segments=64),\n",
    "    iaa.Dropout(p=(0, 0.2)),\n",
    "    iaa.Affine(rotate=(-45, 45))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class image_util:\n",
    "    def __init__ (self, data_dir, biz_label_file_name, photo_biz_file_name):\n",
    "        self.batch_index = 0\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.image_paths = [os.path.join(data_dir,i) for i in os.listdir(data_dir) if i.endswith('.jpg') and not i.startswith(\"._\")]\n",
    "        self.image_len = len(self.image_paths)\n",
    "        self.one_hot = self.read_csv_one_hot(biz_label_file_name)\n",
    "        self.photo_biz = self.photo_to_biz_id(photo_biz_file_name)\n",
    "        \n",
    "#         label_photos = {}\n",
    "#         for path in image_paths:\n",
    "#             img = cv2.imread(path)\n",
    "#             if img is None:\n",
    "#                 continue\n",
    "#             photo_id = os.path.basename(path).split(\".\")[0]\n",
    "#             img = cv2.resize(img,(299,299),interpolation = cv2.INTER_AREA)\n",
    "#             label = one_hot[photo_biz[photo_id]]\n",
    "#             label = tuple(label)\n",
    "#             if label in label_photos:\n",
    "#                 label_photos[label].append(img)\n",
    "#             else:\n",
    "#                 label_photos[label] = [img]\n",
    "#             if len(label_photos) == 50:\n",
    "#                 break\n",
    "#         self.labels = np.asarray(label_photos.keys())\n",
    "#         self.images = np.asarray(label_photos.values())\n",
    "#         print(self.labels.shape)\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        images = []\n",
    "        labels = []\n",
    "        label_photos = {}\n",
    "        if batch_size + self.batch_index * batch_size < self.image_len:\n",
    "            start = self.batch_index\n",
    "            end = batch_size + self.batch_index\n",
    "            for path in self.image_paths[start:end]:\n",
    "                img = cv2.imread(path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                photo_id = os.path.basename(path).split(\".\")[0]\n",
    "                \n",
    "                #img resize & normalization\n",
    "                img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n",
    "                img[:,:,0] = (im[:,:,0] - 103.94) * 0.017\n",
    "                img[:,:,1] = (im[:,:,1] - 116.78) * 0.017\n",
    "                img[:,:,2] = (im[:,:,2] - 123.68) * 0.017\n",
    "                \n",
    "                label = self.one_hot[self.photo_biz[photo_id]]\n",
    "                label = tuple(label)\n",
    "                if label in label_photos:\n",
    "                    label_photos[label] = np.vstack((label_photos[label], [img]))\n",
    "                else:\n",
    "                    label_photos[label] = np.asarray([img])\n",
    "            labels = np.asarray(label_photos.keys())\n",
    "            images = np.asarray(label_photos.values())\n",
    "            self.batch_index += 1\n",
    "            return images, labels\n",
    "        else:\n",
    "            self.batch_index = 0\n",
    "            start = self.batch_index\n",
    "            end = batch_size + self.batch_index\n",
    "            for path in self.image_paths[start:end]:\n",
    "                img = cv2.imread(path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                photo_id = os.path.basename(path).split(\".\")[0]\n",
    "                \n",
    "                #img resize & normalization\n",
    "                img = cv2.resize(img,(224,224),interpolation = cv2.INTER_AREA)\n",
    "                img[:,:,0] = (im[:,:,0] - 103.94) * 0.017\n",
    "                img[:,:,1] = (im[:,:,1] - 116.78) * 0.017\n",
    "                img[:,:,2] = (im[:,:,2] - 123.68) * 0.017\n",
    "                \n",
    "                label = self.one_hot[self.photo_biz[photo_id]]\n",
    "                label = tuple(label)\n",
    "                if label in label_photos:\n",
    "                    label_photos[label] = np.vstack((label_photos[label], [img]))\n",
    "                else:\n",
    "                    label_photos[label] = np.asarray([img])\n",
    "            labels = np.asarray(label_photos.keys())\n",
    "            images = np.asarray(label_photos.values())\n",
    "            return images, labels\n",
    "        \n",
    "    def read_csv_one_hot(self, file_name):\n",
    "        with open(file_name,\"r\") as f:\n",
    "            lines = f.readlines()[1:]\n",
    "        biz_id_to_label = {}\n",
    "        for line in lines:\n",
    "            try:\n",
    "                biz_id_to_label[line.split(\",\")[0]] = np.zeros(9)\n",
    "                for label in line.split(\",\")[1].rstrip().split(' '):\n",
    "                    biz_id_to_label[line.split(\",\")[0]][int(label)]=1\n",
    "            except:\n",
    "                if not line.split(\",\")[1].rstrip():\n",
    "                    continue\n",
    "        return biz_id_to_label\n",
    "    \n",
    "    def photo_to_biz_id(self, file_name):\n",
    "        with open(file_name,\"r\") as f:\n",
    "            lines = f.readlines()[1:]\n",
    "        photo_to_biz = {}\n",
    "        for line in lines:\n",
    "            photo_to_biz[line.split(\",\")[0]] = line.split(\",\")[1].rstrip() \n",
    "        return photo_to_biz\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = image_util('./train_photos', './train.csv', './train_photo_to_biz_ids.csv')\n",
    "inputs.next_batch(16)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_img_list = []\n",
    "for images in inputs.images:\n",
    "    processed_imgs = []\n",
    "    for im in images:\n",
    "        im = cv2.resize(im, (224, 224)).astype(np.float32)\n",
    "        im[:,:,0] = (im[:,:,0] - 103.94) * 0.017\n",
    "        im[:,:,1] = (im[:,:,1] - 116.78) * 0.017\n",
    "        im[:,:,2] = (im[:,:,2] - 123.68) * 0.017\n",
    "        processed_imgs.append(im)\n",
    "    processed_img_list.append(np.asarray(processed_imgs))\n",
    "    \n",
    "processed_img_list = np.asarray(processed_img_list)\n",
    "\n",
    "# ignore augmentation first\n",
    "for i in range(0):\n",
    "    images = im\n",
    "    images = np.expand_dims(images,0)\n",
    "    images_aug = seq.augment_images(images)\n",
    "    images_input = np.concatenate((images_input,images_aug),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DenseNet(reduction=0.5, classes=1000, weights_path='./densenet121_weights_tf.h5')\n",
    "print(model.layers[-1].output_shape)\n",
    "model.layers.pop()\n",
    "model.layers.pop()\n",
    "output = model.layers[-1].output\n",
    "new_model = Model(model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model.layers[-1].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# business features\n",
    "def get_biz_features(images):\n",
    "    biz_features = []\n",
    "    for i, img_list in enumerate(images):\n",
    "        pred = new_model.predict(img_list)\n",
    "        biz_features.append(np.mean(pred, axis=0))\n",
    "    return np.asarray(biz_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 4\n",
    "batch_size = 20\n",
    "display_step = 20\n",
    "# classifier = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "lst_clfs = [LinearSVC() for i in range(9)]\n",
    "for i in range(epoch):\n",
    "    for j in range(inputs.image_len/batch_size):\n",
    "        images, labels = inputs.next_batch(batch_size)\n",
    "        biz_features = get_biz_features(images)\n",
    "        for k in range(9):\n",
    "            clf = lst_clfs[k]\n",
    "            clf.fit(biz_features, labels[:, k])\n",
    "        # use next batch to test\n",
    "        if i*j%20==0:\n",
    "            test_images, test_labels = inputs.next_batch(batch_size)\n",
    "            test_biz_features = get_biz_features(test_images)\n",
    "            accs = []\n",
    "            for k in range(9):\n",
    "                clf = lst_clfs[k]\n",
    "                accs.append(clf.score(test_biz_features, test_labels[:, k]))\n",
    "            print('Epoch:'+str(i)+'  '+'Batch:'+str(j)+'  '+'Accuracy:'+str(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
